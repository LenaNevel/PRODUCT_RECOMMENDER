{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import requests\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PULLING SLUG INFO THAT WILL LEAD TO THE PRODUCT PAGE\n",
    "\n",
    "#credit for this code: https://www.hackerearth.com/fr/practice/notes/praveen97uma/crawling-a-website-that-loads-content-using-javascript-with-selenium-webdriver-in-python/\n",
    "#this code creates a function that gets the browser to scroll down\n",
    "def scrollDown(driver, n_scroll):\n",
    "    body = driver.find_element_by_tag_name(\"body\")\n",
    "    while n_scroll >= 0:\n",
    "        body.send_keys(Keys.PAGE_DOWN)\n",
    "        n_scroll -= 1\n",
    "    return driver\n",
    "\n",
    "#chromedriver needs to be downloaded from https://chromedriver.chromium.org/downloads\n",
    "chrome_path = \"/Users/yelenanevel/Downloads/chromedriver\"\n",
    "#opens the google chrome\n",
    "driver = webdriver.Chrome(executable_path = chrome_path)\n",
    "\n",
    "#this list represents different skin care categories to collect\n",
    "categories = ['all-cleansers',\n",
    "             'all-moisturizers',\n",
    "             'masks-1',\n",
    "             'treatments',\n",
    "             'eye-care',\n",
    "             'sunscreen',\n",
    "             'lip-care']\n",
    "\n",
    "#creating an empty data frame that all the URLs and categories will go in to\n",
    "slugs_df = pd.DataFrame(columns = ['category', 'href'])\n",
    "\n",
    "#looping through all the categories\n",
    "for category in categories:\n",
    "    #the url that leads to the list of products\n",
    "    url = \"https://credobeauty.com/collections/\" + category\n",
    "    driver.get(url)\n",
    "    time.sleep(20)\n",
    "\n",
    "    old_len = 0\n",
    "    while True:\n",
    "        browser = scrollDown(driver, 20) #scroll down the page\n",
    "        time.sleep(10) #give it time to load\n",
    "        slug = driver.find_elements_by_class_name(\"product\") #look for the available info on page\n",
    "        new_len = len(slug)\n",
    "        if old_len == new_len: #if the old length and new length are equal, the bottom of page was reached\n",
    "            break\n",
    "        else:\n",
    "            old_len = new_len\n",
    "    #this gets all the page_soure\n",
    "    html = driver.page_source\n",
    "    #converts it to soup so we can extract info\n",
    "    soup = BeautifulSoup(html)\n",
    "    #finding all the products\n",
    "    page = soup.find_all('div', {'class':\"product\"})\n",
    "\n",
    "    slugs = []\n",
    "    for product in page:\n",
    "        slug = {}\n",
    "        slug['category'] = category\n",
    "        #finding URL under the class: product div\n",
    "        slug['href'] = product.find('a')['href'] #pulls out the slug from the page source\n",
    "        #appending the list with dictionary\n",
    "        slugs.append(slug)\n",
    "    #making a dataframe from list\n",
    "    df = pd.DataFrame(slugs)\n",
    "    #appending this to final dataframe with all the URLs\n",
    "    slugs_df = pd.concat([slugs_df, df], axis = 0, ignore_index = True, sort = True)\n",
    "    \n",
    "#closing the chrome window    \n",
    "driver.close()\n",
    "\n",
    "#saving the final dataframe of URLs in to a csv folder\n",
    "slugs_df.to_csv('../data/credo_product_slugs.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>href</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>all-cleansers</td>\n",
       "      <td>/collections/all-cleansers/products/one-love-o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>all-cleansers</td>\n",
       "      <td>/collections/all-cleansers/products/exfoliatin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>all-cleansers</td>\n",
       "      <td>/collections/all-cleansers/products/josh-roseb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>all-cleansers</td>\n",
       "      <td>/collections/all-cleansers/products/indie-lee-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>all-cleansers</td>\n",
       "      <td>/collections/all-cleansers/products/indie-lee-...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        category                                               href\n",
       "0  all-cleansers  /collections/all-cleansers/products/one-love-o...\n",
       "1  all-cleansers  /collections/all-cleansers/products/exfoliatin...\n",
       "2  all-cleansers  /collections/all-cleansers/products/josh-roseb...\n",
       "3  all-cleansers  /collections/all-cleansers/products/indie-lee-...\n",
       "4  all-cleansers  /collections/all-cleansers/products/indie-lee-..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "slugs_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#GETTING HTML FILES THAT WILL LEAD TO THE PRODUCT PAGE\n",
    "\n",
    "for i in slugs_df.index: #for every url slug we got\n",
    "    url = \"https://credobeauty.com\" + slugs_df.loc[i, 'href']\n",
    "    res = requests.get(url)\n",
    "    time.sleep(20)\n",
    "    if res.status_code != 200:\n",
    "        print('error when requestion {}'.format(url))\n",
    "        break\n",
    "    soup = BeautifulSoup(res.content, 'html.parser')\n",
    "    #going to save it to this path\n",
    "    path = './soups/credosoup' + str(i) + '.html'\n",
    "    with open(path, 'w') as f:\n",
    "        f.write(str(soup))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n",
      "77\n",
      "161\n",
      "204\n",
      "253\n",
      "273\n",
      "611\n"
     ]
    }
   ],
   "source": [
    "#GATHER INFO FROM THE PRODUCT HTML PAGES\n",
    "\n",
    "#opening a new csv file with headers\n",
    "header = ['name', 'brand', 'category', 'price', 'ingredients']\n",
    "\n",
    "with open('../data/credo_product_info.csv', \"w\", newline='') as f:\n",
    "    writer = csv.writer(f, delimiter=',')\n",
    "    writer.writerow(header) # write the header\n",
    "    \n",
    "\n",
    "for i in slugs_df.index:\n",
    "    products = [] #empty list to append the dictionary in to before passing in to a DataFrame\n",
    "    #setting the path to the the html files\n",
    "    path = './soups/credosoup' + str(i) + '.html'\n",
    "    #opening and reading the file\n",
    "    file_path = open(path, 'rb')\n",
    "    file_read = file_path.read()\n",
    "    #creating a new soup from it\n",
    "    soup = BeautifulSoup(file_read, 'html.parser')\n",
    "    #gathering the data from the pages\n",
    "      \n",
    "    try:          \n",
    "        product = {}\n",
    "        product['name'] = str(soup.find('h1', {'class': 'product_name'}).text).split('\\n')[2].strip()\n",
    "        product['brand'] = soup.find('span', {'class': 'vendor'}).text\n",
    "        product['category'] = slugs_df.category[i]\n",
    "        product['price'] = str(soup.find('span', {'class': 'current_price'}).text).split(' ')[1].strip()\n",
    "        product['ingredients'] = soup.find('div', {'class': 'tab tab3 ingredients'}).text\n",
    "\n",
    "\n",
    "            #append the empty list to later make in to a dataframe\n",
    "        products.append(product)\n",
    "        product_df = pd.DataFrame(products) \n",
    "            #append in the csv file that created above\n",
    "        product_df.to_csv('../data/credo_product_info.csv', mode='a', index = False, header = False)\n",
    "    except:\n",
    "        print(i)\n",
    "    \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#i = 50 is a Indie Lee Clarity Kit\n",
    "# i = 77 is a Skin Brush\n",
    "# i = 161 is a The New Normal Kit\n",
    "# i = 204 Indie Lee Clarity Kit\n",
    "# i = 253 is a The \"Clean 5\" Starter Kit\n",
    "\n",
    "#all of these products can be ommitted since they are either already represented individually\n",
    "#or are not a skincare liquid product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
