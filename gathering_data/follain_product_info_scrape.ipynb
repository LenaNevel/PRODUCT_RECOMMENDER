{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "import requests\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#GETTING SLUGS FOR ALL THE PRODUCT PAGES\n",
    "\n",
    "#am able to just do this with requests and not selenium because they have a small amount of products\n",
    "#if it increases or pages are added this code will need to be altered\n",
    "\n",
    "#categories the products fall under on their page\n",
    "categories = ['cleansers',\n",
    "             'toners',\n",
    "             'moisturizers',\n",
    "             'treatments-and-serums',\n",
    "             'masks-exfoliants',\n",
    "             'eye-care',\n",
    "             'lip-care',\n",
    "             'sun-care']\n",
    "\n",
    "slugs_df = pd.DataFrame(columns = ['category', 'href'])   \n",
    "for category in categories:\n",
    "    time.sleep(20)\n",
    "    url = \"https://follain.com/collections/skincare-\" + category + '?sort_by=best-selling'\n",
    "    res = requests.get(url)\n",
    "    \n",
    "    #if there is a fail attempt print the url that's not working and break\n",
    "    if res.status_code != 200:\n",
    "        print('error when requestion {}'.format(url))\n",
    "        break\n",
    "    soup = BeautifulSoup(res.content, 'html.parser')\n",
    "    page = soup.find_all('div', {'class':\"product-grid-item-inner\"})\n",
    "    slugs = []\n",
    "    #pulling the individual slugs for each product\n",
    "    for product in page:\n",
    "        slug = {}\n",
    "        slug['category'] = category\n",
    "        slug['href'] = product.find('a')['href']\n",
    "        slugs.append(slug)\n",
    "    df = pd.DataFrame(slugs)\n",
    "    slugs_df = pd.concat([slugs_df, df], axis = 0, ignore_index = True, sort = True)\n",
    "slugs_df.to_csv('../data/follain_product_slugs.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>href</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cleansers</td>\n",
       "      <td>/collections/skincare-cleansers/products/brigh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cleansers</td>\n",
       "      <td>/collections/skincare-cleansers/products/osea-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cleansers</td>\n",
       "      <td>/collections/skincare-cleansers/products/tata-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cleansers</td>\n",
       "      <td>/collections/skincare-cleansers/products/one-l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cleansers</td>\n",
       "      <td>/collections/skincare-cleansers/products/ursa-...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    category                                               href\n",
       "0  cleansers  /collections/skincare-cleansers/products/brigh...\n",
       "1  cleansers  /collections/skincare-cleansers/products/osea-...\n",
       "2  cleansers  /collections/skincare-cleansers/products/tata-...\n",
       "3  cleansers  /collections/skincare-cleansers/products/one-l...\n",
       "4  cleansers  /collections/skincare-cleansers/products/ursa-..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "slugs_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#GETTING HTML FILES THAT WILL LEAD TO THE PRODUCT PAGE\n",
    "\n",
    "for i in slugs_df.index: #for every url slug we got\n",
    "    time.sleep(20)\n",
    "    url = \"https://follain.com\" + slugs_df.loc[i, 'href']\n",
    "    res = requests.get(url)\n",
    "    if res.status_code != 200:\n",
    "        print('error when requestion {}'.format(url))\n",
    "        break\n",
    "    soup = BeautifulSoup(res.content, 'html.parser')\n",
    "    #going to save it to this path\n",
    "    path = './soups/follainsoup' + str(i) + '.html'\n",
    "    with open(path, 'w') as f:\n",
    "        f.write(str(soup))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#GATHER INFO FROM THE PRODUCT HTML PAGES\n",
    "\n",
    "#opening a new csv file with headers\n",
    "header = ['name', 'brand', 'category', 'price', 'ingredients']\n",
    "\n",
    "with open('../data/follain_product_info.csv', \"w\", newline='') as f:\n",
    "    writer = csv.writer(f, delimiter=',')\n",
    "    writer.writerow(header) # write the header\n",
    "    \n",
    "\n",
    "for i in slugs_df.index:\n",
    "    products = [] #empty list to append the dictionary in to before passing in to a DataFrame\n",
    "    #setting the path to the the html files\n",
    "    path = './soups/follainsoup' + str(i) + '.html'\n",
    "    #opening and reading the file\n",
    "    file_path = open(path, 'rb')\n",
    "    file_read = file_path.read()\n",
    "    #creating a new soup from it\n",
    "    soup = BeautifulSoup(file_read, 'html.parser')\n",
    "    #gathering the data from the pages\n",
    "      \n",
    "              \n",
    "    product = {}\n",
    "    product['name'] = soup.find('h1', {'class': 'product-single-name'}).text\n",
    "    product['brand'] = soup.find('a', {'class': 'product-single-vendor'}).text\n",
    "    product['category'] = slugs_df.category[i]\n",
    "    product['price'] = soup.find('div', {'class': 'product-single-price'}).text\n",
    "    \n",
    "    list_of_ingredients = []\n",
    "    for i in soup.find_all('span', {'class': 'ingredient-item'}):\n",
    "        list_of_ingredients.append(i.text)\n",
    "    product['ingredients'] = list_of_ingredients\n",
    "    \n",
    "    \n",
    "        #append the empty list to later make in to a dataframe\n",
    "    products.append(product)\n",
    "    product_df = pd.DataFrame(products) \n",
    "        #append in the csv file that created above\n",
    "    product_df.to_csv('../data/follain_product_info.csv', mode='a', index = False, header = False)\n",
    "\n",
    "    \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
